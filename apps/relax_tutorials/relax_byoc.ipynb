{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax BYOC Tutorial\n",
    "\n",
    "  Bring-Your-Own-Codegen (BYOC) is the interface that TVM offers to enable integration of external libraries like TensorRT, Cutlass, DNNL, etc.  This doc aims to provide high-level idea about how to use BYOC in Relax, how to integrate new library, and what is the difference with Relay BYOC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-level Guide\n",
    "\n",
    "### Setup\n",
    "\n",
    "  Build TVM with your BYOC in `config.cmake`. \n",
    "  For example, if you want to use TensorRT:\n",
    "\n",
    "```python\n",
    "set(USE_TENSORRT_CODEGEN ON)\n",
    "set(USE_TENSORRT_RUNTIME ON)\n",
    "```\n",
    "\n",
    "### Basic workflow\n",
    "\n",
    "  Relax BYOC offloads the computation at Relax function level. If you have a part of graph you want to leverage BYOC, e2e workflow example is as follows:\n",
    "\n",
    "(1) Partition a graph into a set of relax functions and annotate the relax function that you want to offload with a target codegen and its global symbol. This example assumes TensorRT. Partitioning can be done either manually or by another pass (e.g., pattern matching. see Offload with pattern matching for detail). Note that target codegen should be able to handle every operator in the annotated function. It will throws a compilation error otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.script.parser import relax as R, tir as T\n",
    "\n",
    "# This example wants to offload `byoc_func` to TensorRT\n",
    "@tvm.script.ir_module\n",
    "class InputModule:\n",
    "    @R.function\n",
    "    def byoc_func(\n",
    "        x: R.Tensor((16, 16), \"float32\"), y: R.Tensor((16, 16), \"float32\")\n",
    "    ) -> R.Tensor((16, 16), \"float32\"):\n",
    "        # Annotate a function you want to offload\n",
    "        R.func_attr({\"Codegen\": \"tensorrt\", \"global_symbol\": \"byoc_func\"})\n",
    "        z1 = R.multiply(x, y)\n",
    "        z2 = R.add(z1, z1)\n",
    "        z3 = R.add(z1, z2)\n",
    "        return z3\n",
    "\n",
    "    @R.function\n",
    "    def tvm_func(\n",
    "        x: R.Tensor((16, 16), \"float32\"), w: R.Tensor((16, 16), \"float32\")\n",
    "    ) -> R.Tensor((16, 16), \"float32\"):\n",
    "        gv0 = R.multiply(x, w)\n",
    "        gv1 = R.add(x, gv0)\n",
    "        return gv1\n",
    "\n",
    "    @R.function\n",
    "    def main(\n",
    "        x: R.Tensor((16, 16), \"float32\"), y: R.Tensor((16, 16), \"float32\")\n",
    "    ) -> R.Tensor((16, 16), \"float32\"):\n",
    "        lv0 = byoc_func(x, y)\n",
    "        lv1 = tvm_func(x, lv0)\n",
    "        return lv1\n",
    "\n",
    "mod = InputModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Perform `RunCodegen` pass to produce the external runtime module for the annotated relax functions. Internally, it will invoke codegen based on the annotation and attach the generated BYOC runtime module in the IRModule attribute so that executor can link it together. Then, it will also convert users of annotated functions from relax function calls to packed function calls with the attached global symbol in order to call into BYOC runtime. Once BYOC functions are consumed, they are no longer necessary. Thus, `RunCodegen` removes them by using the `RemoveUnusedFunctions` pass at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@R.function\n",
      "def main(x: R.Tensor((16, 16), dtype=\"float32\"), y: R.Tensor((16, 16), dtype=\"float32\")) -> R.Tensor((16, 16), dtype=\"float32\"):\n",
      "    # block 0\n",
      "    lv0 = R.call_tir(\"byoc_func\", (x, y), (16, 16), dtype=\"float32\")\n",
      "    lv1: R.Tensor((16, 16), dtype=\"float32\") = tvm_func(x, lv0)\n",
      "    return lv1\n",
      "    \n",
      "\n",
      "@R.function\n",
      "def main(x1: R.Tensor((16, 16), dtype=\"float32\"), w: R.Tensor((16, 16), dtype=\"float32\")) -> R.Tensor((16, 16), dtype=\"float32\"):\n",
      "    # block 0\n",
      "    gv0: R.Tensor((16, 16), dtype=\"float32\") = R.multiply(x1, w)\n",
      "    gv1: R.Tensor((16, 16), dtype=\"float32\") = R.add(x1, gv0)\n",
      "    return gv1\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_mod = relax.transform.RunCodegen()(mod)\n",
    "print(new_mod)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the function annotated with TensorRT is consumed  and its users are converted from relax function calls to the packed function calls with the given global symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"external_mods\": [runtime.Module(0x35149e8)]}\n"
     ]
    }
   ],
   "source": [
    "print(new_mod.attrs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the runtime module generated by TensorRT codegen is attached in the IRModule attribute.\n",
    "\n",
    "(3) Apply the rest of pass sequence (e.g., lowering, MetaSchedule tuning) and run the final IRModule with the selected executor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-09 16:22:23 [INFO] [task_scheduler.cc:260] Task #1 has finished. Remaining task(s): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiply</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>1.5697</td>\n",
       "      <td>1.5697</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1632</td>\n",
       "      <td>1.5683</td>\n",
       "      <td>1.5683</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name    FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   multiply     256         1            0.1631          1.5697    \n",
       "1        add     256         1            0.1632          1.5683    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0                  1.5697         4       Y   \n",
       "1                  1.5683         4       Y   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-09 16:22:23 [DEBUG] [task_scheduler.cc:318] \n",
      " ID |     Name | FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "  0 | multiply |  256 |      1 |         0.1631 |       1.5697 |                1.5697 |      4 |    Y \n",
      "  1 |      add |  256 |      1 |         0.1632 |       1.5683 |                1.5683 |      4 |    Y \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Total trials: 8\n",
      "Total latency (us): 3.13802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tvm.relax.testing import transform\n",
    "import tempfile\n",
    "from tvm.relax.transform.tuning_api import Trace\n",
    "import numpy as np\n",
    "\n",
    "# Target gpu\n",
    "target_str = \"nvidia/geforce-rtx-3070\"\n",
    "target = tvm.target.Target(target_str)\n",
    "dev = tvm.cuda()\n",
    "\n",
    "with tempfile.TemporaryDirectory() as work_dir:\n",
    "    with target, tvm.transform.PassContext(trace=Trace(mod), opt_level=3):\n",
    "        # Apply the rest of pass seq\n",
    "        rest_seq = tvm.transform.Sequential([ \n",
    "            transform.LowerWithRelayOpStrategyPass(target),\n",
    "            relax.transform.MetaScheduleTuneIRMod(params={}, work_dir=work_dir, max_trials_global=8),\n",
    "            relax.transform.MetaScheduleApplyDatabase(work_dir),\n",
    "        ])\n",
    "        final_mod = rest_seq(new_mod)\n",
    "\n",
    "# Build and run `final_mod` with the chosen executor\n",
    "ex = relax.vm.build(final_mod, target, params={})\n",
    "vm = relax.VirtualMachine(ex, dev)\n",
    "\n",
    "np0 = np.random.rand(16, 16).astype(np.float32)\n",
    "np1 = np.random.rand(16, 16).astype(np.float32)\n",
    "data0 = tvm.nd.array(np0, dev)\n",
    "data1 = tvm.nd.array(np1, dev)\n",
    "inputs = [data0, data1]\n",
    "out = vm[\"main\"](*inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offload with pattern matching\n",
    "  With the same principle in mind, Relax offers two convenient passes that you can easily group your operators and annotate your target functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
